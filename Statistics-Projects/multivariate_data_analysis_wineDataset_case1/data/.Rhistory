knn.Fit.3 <- train(Y ~ ., data = train3, method = "knn", trControl = knn.ctrl.3, preProcess = c("center","scale"), tuneLength = parameter.k)
#
#Output of kNN fit (Only for Admin Panel)
knn.Fit.3
knn.tra.acc3 <- max(knn.Fit.3$results$Accuracy)
plot(knn.Fit.3)
#Prediction
knn.Predict.3 <- predict(knn.Fit.3,newdata = test3 )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knn.Predict.3, test3$Y) -> cm.knn3
cm.knn3
knn.test.acc3 <- cm.knn3$overall[1]
# OVERALL ACCURACY RESULTS for kNN (IF ALL SCENARIO ARE READY!)
cat(sprintf("Overall Results
\nScenario1 (Prediction of 'Number of Errors')\nThe training accuracy is: %f\nThe testing accuracy is: %f
\nScenario2 (Prediction of 'Error'/'Single Error'/'Multiple Errors')\nThe training accuracy is: %f\nThe testing accuracy is: %f
\nScenario3 (Prediction of 'No Error'/'Error')\nThe training accuracy is: %f\nThe testing accuracy is: %f",
knn.tra.acc1, knn.test.acc1, knn.tra.acc2, knn.test.acc2, knn.tra.acc3, knn.test.acc3))
# Execution Time
end.time.knn <- Sys.time()
time.taken.knn <- end.time.knn - start.time.knn
time.taken.knn
#
#
#########################################################
# RANDOM FORESTS ALGORITHM for ERROR PREDICTION #########
#########################################################
start.time.rf <- Sys.time()
#
parameter.rf = 5 #Number of trials for RF algorithm
# RF - SCENARIO #1: Predict Number of Erros with Possibilities
##############################################################
rf.train.1 <- data_ex1[,names(train1) != "Y"]
rf.preProcValues.1 <- preProcess(x = rf.train.1,method = c("center", "scale"))
#preProcValues.1
set.seed(1000)
rf.ctrl.1 <- trainControl(method="repeatedcv",repeats = 3)
rf.Fit.1 <- train(Y ~ ., data = train1, method = "rf", trControl = rf.ctrl.1, preProcess = c("center","scale"), tuneLength = parameter.rf)
#
#Output of RF fit (Only for Admin Panel)
rf.Fit.1
rf.tra.acc1 <- max(rf.Fit.1$results$Accuracy)
plot(rf.Fit.1)
#Prediction
rf.Predict.1 <- predict(rf.Fit.1,newdata = test1 )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(rf.Predict.1, test1$Y) -> cm.rf1
cm.rf1
rf.test.acc1 <- cm.rf1$overall[1]
# RF - SCENARIO #2: Predict No/Single/Multiple Errors with Possibilities
########################################################################
rf.train.2 <- data_sce2[,names(train2) != "Y"]
rf.preProcValues.2 <- preProcess(x = rf.train.2,method = c("center", "scale"))
#preProcValues.1
set.seed(1000)
rf.ctrl.2 <- trainControl(method="repeatedcv",repeats = 3)
rf.Fit.2 <- train(Y ~ ., data = train2, method = "rf", trControl = rf.ctrl.2, preProcess = c("center","scale"), tuneLength = parameter.rf)
#
#Output of RF fit (Only for Admin Panel)
rf.Fit.2
rf.tra.acc2 <- max(rf.Fit.2$results$Accuracy)
plot(rf.Fit.2)
#Prediction
rf.Predict.2 <- predict(rf.Fit.2,newdata = test2 )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(rf.Predict.2, test2$Y) -> cm.rf2
cm.rf2
rf.test.acc2 <- cm.rf2$overall[1]
# RF - SCENARIO #3: Predict 'No Error'/'Yes Error' with Possibilities
######################################################################
rf.train.3 <- data_sce3[,names(train3) != "Y"]
rf.preProcValues.3 <- preProcess(x = rf.train.3,method = c("center", "scale"))
#preProcValues.1
set.seed(1000)
rf.ctrl.3 <- trainControl(method="repeatedcv",repeats = 3)
rf.Fit.3 <- train(Y ~ ., data = train3, method = "rf", trControl = rf.ctrl.3, preProcess = c("center","scale"), tuneLength = parameter.rf)
#
#Output of RF fit (Only for Admin Panel)
rf.Fit.3
rf.tra.acc3 <- max(rf.Fit.3$results$Accuracy)
plot(rf.Fit.3)
#Prediction
rf.Predict.3 <- predict(rf.Fit.3,newdata = test3 )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(rf.Predict.3, test3$Y) -> cm.rf3
cm.rf3
rf.test.acc3 <- cm.rf3$overall[1]
# OVERALL ACCURACY RESULTS for RF (IF ALL SCENARIO ARE READY!)
cat(sprintf("Overall Results
\nScenario1 (Prediction of 'Number of Errors')\nThe training accuracy is: %f\nThe testing accuracy is: %f
\nScenario2 (Prediction of 'Error'/'Single Error'/'Multiple Errors')\nThe training accuracy is: %f\nThe testing accuracy is: %f
\nScenario3 (Prediction of 'No Error'/'Error')\nThe training accuracy is: %f\nThe testing accuracy is: %f",
rf.tra.acc1, rf.test.acc1, rf.tra.acc2, rf.test.acc2, rf.tra.acc3, rf.test.acc3))
# Execution Time
end.time.rf <- Sys.time()
time.taken.rf <- end.time.rf - start.time.rf
time.taken.rf
#
#
###################################################
# RESULT CHECKS & PRE-PROCESSING FOR DCML #########
###################################################
# ACCURACY TABLES
# Accuracy for Naive Bayes
accuracy.nb <- matrix(c(tra.acc1*100, tra.acc2*100, tra.acc3*100, test.acc1*100, test.acc2*100, test.acc3*100),ncol=3,byrow=TRUE)
rownames(accuracy.nb) <- c("Training","Testing")
colnames(accuracy.nb) <- c("Scenario1","Scenario2","Scenario3")
round(accuracy.nb,1)
# Accuracy for k-NN
accuracy.knn <- matrix(c(knn.test.acc1*100,knn.test.acc2*100,knn.test.acc3*100,knn.tra.acc1*100,knn.tra.acc2*100,knn.tra.acc3*100),ncol=3,byrow=TRUE)
rownames(accuracy.knn) <- c("Training","Testing")
colnames(accuracy.knn) <- c("Scenario1","Scenario2","Scenario3")
round(accuracy.knn,1)
# Accuracy for RF
accuracy.rf <- matrix(c(rf.test.acc1*100,rf.test.acc2*100,rf.test.acc3*100,rf.tra.acc1*100,rf.tra.acc2*100,rf.tra.acc3*100),ncol=3,byrow=TRUE)
rownames(accuracy.rf) <- c("Training","Testing")
colnames(accuracy.rf) <- c("Scenario1","Scenario2","Scenario3")
round(accuracy.rf,1)
# Global Accuracy List
global.accuracy <- list("Naive Bayes Algorithm"=accuracy.nb,"k-Nearest Neighbor Algorithm"=accuracy.knn,"Random Forests Algorithm"=accuracy.rf)
global.accuracy[] <- lapply(global.accuracy,round,1)
# ALGORITHM EXECUTION LIST
exec.time.list <- cbind(time.taken.nb,time.taken.knn,time.taken.rf)
colnames(exec.time.list) <- c("Naive-Bayes","kNN","Random Forests")
rownames(exec.time.list) <- c("Execution Time")
exec.time.list
# Total Execution Time
end.time.global <- Sys.time()
time.taken.global <- end.time.global - start.time.global
# GLOBAL RESULTS
global.accuracy
exec.time.list
time.taken.global
#END OF THE PROCESS#
cor.plot(data)
attach(attitude)
View(attitude)
mydata <- data.frame(attitude$complaints, attitude$learning, attitude$raises)
summary(mydata)
describe(mydata)
install.packages("mvnormtest")
transpose_attitude <- t(mydata)
mshapiro.test(transpose_attitude)
#2. Testing Positive Determinant
CovAttitude <- cov(attitude)
det(CovAttitude)
group <- rep(c("male","female"),c(15,15))
factor(group)
group
library(mvnormtest)
transpose_attitude <- t(mydata)
mshapiro.test(transpose_attitude)
install.packages("biotools")
library(biotools)
boxM(attitude,group)
library(biotools)
install.packages("biotools")
library(biotools)
boxM(attitude,group)
boxM <-
function(data, grouping)
{
if (!inherits(data, c("data.frame", "matrix")))
stop("'data' must be a numeric data.frame or matrix!")
if (length(grouping) != nrow(data))
stop("incompatible dimensions!")
dname <- deparse(substitute(data))
data <- as.matrix(data)
grouping <- as.factor(as.character(grouping))
p <- ncol(data)
nlev <- nlevels(grouping)
lev <- levels(grouping)
dfs <- tapply(grouping, grouping, length) - 1
if (any(dfs < p))
warning("there are one or more levels with less observations than variables!")
mats <- aux <- list()
for(i in 1:nlev) {
mats[[i]] <- cov(data[grouping == lev[i], ])
aux[[i]] <- mats[[i]] * dfs[i]
}
names(mats) <- lev
pooled <- Reduce("+", aux) / sum(dfs)
logdet <- log(unlist(lapply(mats, det)))
minus2logM <- sum(dfs) * log(det(pooled)) - sum(logdet * dfs)
sum1 <- sum(1 / dfs)
Co <- (((2 * p^2) + (3 * p) - 1) / (6 * (p + 1) *
(nlev - 1))) * (sum1 - (1 / sum(dfs)))
X2 <- minus2logM * (1 - Co)
dfchi <- (choose(p, 2) + p) * (nlev - 1)
pval <- pchisq(X2, dfchi, lower.tail = FALSE)
out <- structure(
list(statistic = c("Chi-Sq (approx.)" = X2),
parameter = c(df = dfchi),
p.value = pval,
cov = mats, pooled = pooled, logDet = logdet,
data.name = dname,
method = " Box's M-test for Homogeneity of Covariance Matrices"
),
class = c("htest", "boxM")
)
return(out)
}
boxM(attitude,group)
group <- rep(c("male","female"),c(15,15))
factor(group)
group
boxM(attitude,group)
boxM(attitude,group)
CovAttitude <- cov(myadata)
det(CovAttitude)
mydata <- data.frame(attitude$complaints, attitude$learning, attitude$raises)
transpose_attitude <- t(mydata)
mshapiro.test(transpose_attitude)
CovAttitude <- cov(myadata)
det(CovAttitude)
CovAttitude <- cov(mydata)
det(CovAttitude)
group <- rep(c("male","female"),c(15,15))
factor(group)
group
boxM(mydata,group)
install.package("gplots")
library(gplots)
plotmeans(mydata.complaints ~ group, data=mydata, ylim=c(0,100), xlab="Groups",
legends=c("Males","Females"), main="Attitude", connect=FALSE, mean.labels = TRUE,
col=NULL, p=1.0)
summary(mydata)
plotmeans(attitude.complaints ~ group, data=mydata, ylim=c(0,100), xlab="Groups",
legends=c("Males","Females"), main="Attitude", connect=FALSE, mean.labels = TRUE,
col=NULL, p=1.0)
plotmeans(attitude.learning ~ group, data=mydata, ylim=c(0,100), xlab="Groups",
legends=c("Males","Females"), main="Attitude", connect=FALSE, mean.labels = TRUE,
col=NULL, p=1.0)
plotmeans(attitude.raises ~ group, data=mydata, ylim=c(0,100), xlab="Groups",
legends=c("Males","Females"), main="Attitude", connect=FALSE, mean.labels = TRUE,
col=NULL, p=1.0)
install.packages("ICSNP")
library(ICSNP)
HotellingsT2(mydata[1:15,], mydata[16:30,])
install.packages("car")
install.packages("car")
library(car)
data(Baumann) #Baumann education data
attach(Baumann)
?Baumann
install.packages("psych")
install.packages("psych")
library("psych")
ICC(Baumann)
library("psych")
ICC(Baumann)
ICC(Baumann[,4:6])
Y = cbind(post.test1, post.test2, post.test3)
group = factor(group) #encode group as a categoriacal variable
Y = cbind(post.test1, post.test2, post.test3)
attach(Baumann)
ICC(Baumann[,4:6])
group = factor(group) #encode group as a categoriacal variable
Y = cbind(post.test1, post.test2, post.test3)
View(Baumann)
View(Baumann)
View(Baumann)
Y = cbind(post.test.1, post.test.2, post.test.3)
Baumann.manova = manova(Y-group)
Baumann.manova = manova(Y~group)
Baumann.manova = manova(Y~group)
group = factor(group) #encode group as a categoriacal variable
Y = cbind(post.test.1, post.test.2, post.test.3)
Baumann.manova = manova(Y~group)
data(Baumann) #Baumann education data
library(car)
data(Baumann) #Baumann education data
attach(Baumann)
library("psych")
ICC(Baumann[,4:6])
group = factor(group) #encode group as a categoriacal variable
Y = cbind(post.test.1, post.test.2, post.test.3)
Baumann.manova = manova(Y~group)
summary(Baumann.manova, test="wilks")
summary(Baumann.manova, test="Wilks")
summary(Baumann.manova, test="Wilks")
summary(Baumann.manova, test="Pillai")
summary(Baumann.manova, test="Wilks")
summary(Baumann.manova, test="Hotelling-Lawley")
summary(Baumann.manova, test="Roy")
data(Soils)
data(Soils)
attach(Soils)
View(Soils)
install.packages("MASS")
install.packages("MASS")
library("MASS", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
Countour <- factor(Contour)
Contour
options(scipen=999)
Depth <- factor(Depth)
Depth
soils.mod <- lm(cbind(pH,Dens,Conduc)~Contour+Depth+Contour*Depth-1,data=Soils)
summary(soils.mod)
wilks <- Manova(soils.mod, multivariate=TRUE, type=c("III"), test="Wilks"))
wilks <- Manova(soils.mod, multivariate=TRUE, type=c("III"), test="Wilks")
Manova(soils.mod, multivariate=TRUE, type=c("III"), test=("Wilks"))
Manova(soils.mod, multivariate=TRUE, type=c("III"), test=("Pillai"))
Manova(soils.mod, multivariate=TRUE, type=c("III"), test=("Hotelling-Lawley"))
Manova(soils.mod, multivariate=TRUE, type=c("III"), test=("Roy"))
library(foreign)
library(foreign)
setwd("/Users/ugur/Desktop/R/myprojects/END620")
setwd("/Users/ugur/Desktop/R/myprojects/END620/data")
data0 <-  read.spss("koro.sav")
View(data0)
View(data0)
summary(data0)
describe(data)
describe(data0)
describe(data0)
str(data0)
str(data0)
setwd("/Users/ugur/Desktop/R/myprojects/END620/data")
data0 <-  read.spss("koro.sav")
#Data Details
summary(data0)
str(data0)
plot(data0)
plot(data0$subject)
plot(data0$group)
data0 <-  read.spss("wolves.sav")
summary(data0)
str(data0)
plot(data0$group)
plot(data0$location)
plot(data0$x1)
# PCA
#Directory Set and Data Uplaod
setwd("/Users/ugur/Desktop/R/myprojects/END620/data")
# Importing the dataset
dataset = read.csv('Wine.csv')
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Customer_Segment, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-14] = scale(training_set[-14])
test_set[-14] = scale(test_set[-14])
# Applying PCA
# install.packages('caret')
library(caret)
# install.packages('e1071')
library(e1071)
pca = preProcess(x = training_set[-14], method = 'pca', pcaComp = 2)
training_set = predict(pca, training_set)
training_set = training_set[c(2, 3, 1)]
test_set = predict(pca, test_set)
test_set = test_set[c(2, 3, 1)]
# Fitting SVM to the Training set
# install.packages('e1071')
library(e1071)
classifier = svm(formula = Customer_Segment ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3])
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('PC1', 'PC2')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Training set)',
xlab = 'PC1', ylab = 'PC2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('PC1', 'PC2')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3], main = 'SVM (Test set)',
xlab = 'PC1', ylab = 'PC2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
# LDA
# Importing the dataset
dataset = read.csv('Wine.csv')
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Customer_Segment, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-14] = scale(training_set[-14])
test_set[-14] = scale(test_set[-14])
# Applying LDA
library(MASS)
lda = lda(formula = Customer_Segment ~ ., data = training_set)
training_set = as.data.frame(predict(lda, training_set))
training_set = training_set[c(5, 6, 1)]
test_set = as.data.frame(predict(lda, test_set))
test_set = test_set[c(5, 6, 1)]
# Fitting SVM to the Training set
# install.packages('e1071')
library(e1071)
classifier = svm(formula = class ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3])
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('x.LD1', 'x.LD2')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Training set)',
xlab = 'LD1', ylab = 'LD2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('x.LD1', 'x.LD2')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3], main = 'SVM (Test set)',
xlab = 'LD1', ylab = 'LD2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
library(caTools)
set.seed(123)
split = sample.split(dataset$Customer_Segment, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-14] = scale(training_set[-14])
test_set[-14] = scale(test_set[-14])
# Applying LDA
library(MASS)
lda = lda(formula = Customer_Segment ~ ., data = training_set)
training_set = as.data.frame(predict(lda, training_set))
training_set = training_set[c(5, 6, 1)]
test_set = as.data.frame(predict(lda, test_set))
test_set = test_set[c(5, 6, 1)]
# Fitting SVM to the Training set
# install.packages('e1071')
library(e1071)
classifier = svm(formula = class ~ .,
data = training_set,
type = 'C-classification',
kernel = 'linear')
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3])
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('x.LD1', 'x.LD2')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'SVM (Training set)',
xlab = 'LD1', ylab = 'LD2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('x.LD1', 'x.LD2')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3], main = 'SVM (Test set)',
xlab = 'LD1', ylab = 'LD2',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))
points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))
